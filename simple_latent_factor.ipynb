{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a4f625-225f-47a6-80a0-52c689d325a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 5920,
     "status": "ok",
     "timestamp": 1732242186707,
     "user": {
      "displayName": "Tobias Zierl",
      "userId": "15744251128815029584"
     },
     "user_tz": 480
    },
    "id": "13a4f625-225f-47a6-80a0-52c689d325a8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e332da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "\n",
    "def SSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "1e-06\n",
      "2.028340318325888\n",
      "1e-05\n",
      "1.6938332223303925\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('Amazon_Fashion.jsonl.gz', compression='gzip', lines = True)\n",
    "\n",
    "df = df.sort_values(by = \"timestamp\").drop_duplicates(subset= [\"user_id\", \"asin\"], keep = \"last\")\n",
    "\n",
    "df = df.sample(df.shape[0], replace= False) #shuffle data through sampling without replacement\n",
    "\n",
    "allRatings = df.get([\"user_id\", \"asin\", \"rating\"])\n",
    "allRatings_filtered = allRatings[allRatings['user_id'].map(allRatings['user_id'].value_counts()) > 0] \n",
    "#.take(np.arange(50000))\n",
    "\n",
    "\n",
    "allRatings_numpy = allRatings_filtered.to_numpy()\n",
    "\n",
    "training_size = int(allRatings_numpy.size * 0.9)\n",
    "test_size = allRatings_numpy.size - training_size\n",
    "\n",
    "ratingsTrain = allRatings_numpy[:training_size]\n",
    "ratingsValid = allRatings_numpy[-test_size:]\n",
    "\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "\n",
    "\n",
    "\n",
    "N = ratingsTrain.shape[0]\n",
    "nUsers = len(ratingsPerUser)\n",
    "nItems = len(ratingsPerItem)\n",
    "users = list(ratingsPerUser.keys())\n",
    "items = list(ratingsPerItem.keys())\n",
    "\n",
    "\n",
    "alpha_base = sum([r for _, _, r in ratingsTrain]) / ratingsTrain.shape[0]\n",
    "alpha = alpha_base\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases.get(user, 0) + itemBiases.get(item, 0)\n",
    "\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n",
    "\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in ratingsTrain]\n",
    "    cost = SSE(predictions, labels)\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(ratingsTrain)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for u,i,r in ratingsTrain:\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - r\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)\n",
    "\n",
    "print(\"hi\")\n",
    "\n",
    "labels = [r for _, _, r in ratingsTrain]\n",
    "lamb = 0.00001795\n",
    "for i in np.power(10., np.linspace(-6, -5, 2)):\n",
    "    alpha = alpha_base\n",
    "    userBiases = defaultdict(float)\n",
    "    itemBiases = defaultdict(float)\n",
    "    lamb = i\n",
    "    result = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0] * (nUsers + nItems), derivative, args=(labels, lamb))\n",
    "    unpack(result[0])\n",
    "\n",
    "    validMSE = sum((prediction(u,b) - r) ** 2 for u, b, r in ratingsValid) /len(ratingsValid)\n",
    "    print(lamb)\n",
    "    print(validMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cdcbe",
   "metadata": {},
   "source": [
    "### Results of Analysis\n",
    "\n",
    "#### Parameters and Setup:\n",
    "- **Filter**: Only users with at least k reviews (as well for training as for testing)\n",
    "- **Dataset Size**: 50,000 reviews\n",
    "- **Training Split**: 90%\n",
    "\n",
    "#### Lambda Values and Results:\n",
    "\n",
    "| **Lambda**           | **Result**           |\n",
    "|-----------------------|----------------------|\n",
    "| 1e-10                | 1.8639491452201058  |\n",
    "| 1e-09                | 1.8900200977636963  |\n",
    "| 1e-08                | 1.8607871149606283  |\n",
    "| 1e-07                | 1.8761312052228225  |\n",
    "| 1e-06                | 1.8313797079517349  |\n",
    "| 1e-05                | 1.7754904375261358  |\n",
    "| 0.0001               | 1.7256298986720695  |\n",
    "| 0.001                | 1.7244053347977821  |\n",
    "| 0.01                 | 1.7264580268739516  |\n",
    "| 0.0005623413251903491 | 1.72385253847142    |\n",
    "| 0.0031622776601683794 | 1.7256362562196657 |\n",
    "| 0.01778279410038923  | 1.7264580313614348 |\n",
    "| 0.1                  | 1.726710757329759   |\n",
    "\n",
    "##### Only Users with at Least 3 Reviews:\n",
    "| **Lambda**           | **Result**           |\n",
    "|-----------------------|----------------------|\n",
    "| 1e-05                | 1.8536334629174254  |\n",
    "| 5.623413251903491e-05 | 1.814955153595779   |\n",
    "| 0.00031622776601683794 | 1.811577437007883  |\n",
    "| 0.0017782794100389228 | 1.814452901682741  |\n",
    "| 0.01                 | 1.8162453086318369  |\n",
    "\n",
    "\n",
    "##### Only Users with at Least 4 Reviews:\n",
    "| **Lambda**           | **Result**           |\n",
    "|-----------------------|----------------------|\n",
    "| 1e-05                | 1.6352282627340333  |\n",
    "| 5.623413251903491e-05 | 1.6000952481461368  |\n",
    "| 0.00031622776601683794 | 1.5973304474433379 |\n",
    "| 0.0017782794100389228 | 1.600359785941214  |\n",
    "| 0.01                 | 1.6012302843086172  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Analysis 2\n",
    "\n",
    "#### Dataset Details:\n",
    "- **Training Data**: 50,000 samples\n",
    "- **Testing Data**: 5 samples\n",
    "\n",
    "#### Experiments and Results:\n",
    "\n",
    "##### **Train on Users with > 2 Reviews, Test Without Filter**\n",
    "| **Lambda**           | **Result**           |\n",
    "|-----------------------|----------------------|\n",
    "| 1e-05                | 2.222831108785055   |\n",
    "| 5.623413251903491e-05 | 2.2016408675758536  |\n",
    "| 0.00031622776601683794 | 2.212174761502155  |\n",
    "| 0.0017782794100389228 | 2.2222240581797887  |\n",
    "| 0.01                 | 2.225215715699154   |\n",
    "\n",
    "##### **Train on Users with > 1 Review, Test Without Filter**\n",
    "| **Lambda**           | **Result**           |\n",
    "|-----------------------|----------------------|\n",
    "| 1e-05                | 2.015386428126356   |\n",
    "| 5.623413251903491e-05 | 1.990013039961254   |\n",
    "| 0.00031622776601683794 | 1.993702501227149  |\n",
    "| 0.0017782794100389228 | 2.000484144770286  |\n",
    "| 0.01                 | 2.0028333420670346  |\n",
    "\n",
    "##### **Without Any Filter**\n",
    "| **Lambda**           | **Result**           |\n",
    "|-----------------------|----------------------|\n",
    "| 1e-05                | 2.031011005290374   |\n",
    "| 5.623413251903491e-05 | 2.0365455804545265  |\n",
    "| 0.00031622776601683794 | 1.9833165326701572 |\n",
    "| 0.0017782794100389228 | 1.9895842557669083 |\n",
    "| 0.01                 | 1.991673487316493   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Oben waren noch Fehler wegen dem abgeschnitten Datenset mit 50 k Daten und ohne Duplikate rausfiltern)\n",
    "\n",
    "Aufpassen, du trainierst auf allen Daten und dann testest du. D.h. die Test-Daten hat dein Model schon gesehen.\n",
    "\n",
    "Always testing without filter\n",
    "\n",
    "Results of Analysis 3 (11/26)\n",
    "1e-06\n",
    "1.958840587899823\n",
    "0.0001\n",
    "1.9042846821573745\n",
    "\n",
    "\n",
    "Without removing duplicates\n",
    "\n",
    "Training only with users with > 1 Reviews\n",
    "1e-06\n",
    "2.0204436343979744\n",
    "1e-05\n",
    "1.7690549760084189\n",
    "0.0001\n",
    "2.0204436362419846\n",
    "0.001\n",
    "2.0247716234397815\n",
    "0.01\n",
    "2.031464608916076\n",
    "\n",
    "Trainig only with users with > 2 Reviews\n",
    "1e-06\n",
    "1.9150226365828007\n",
    "1e-05\n",
    "2.0449452107480512\n",
    "0.0001\n",
    "2.0589736519434862\n",
    "0.001\n",
    "2.0652982331144494\n",
    "0.01\n",
    "2.0662966165369547"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b5e02",
   "metadata": {},
   "source": [
    "After removing duplicates\n",
    "Aufpassen, du trainierst auf allen Daten und dann testest du. D.h. die Test-Daten hat dein Model schon gesehen.\n",
    "\n",
    "Always testing without a filter\n",
    "\n",
    "Without any filter:\n",
    "\n",
    "1e-06\n",
    "1.1491704725164174\n",
    "0.0001\n",
    "1.9613899550708291\n",
    "\n",
    "1e-06 (lamda)\n",
    "2.01893340737324 (MSE)\n",
    "1e-05\n",
    "2.003078705861867\n",
    "0.0001\n",
    "1.9804709053131913\n",
    "0.001\n",
    "1.9899034780528717\n",
    "0.01\n",
    "1.993274948440368\n",
    "\n",
    "Training with users with > 1 Reviews\n",
    "1e-06\n",
    "2.0725830805463645\n",
    "1e-05\n",
    "2.0725830784036883\n",
    "0.0001\n",
    "2.072583082700361\n",
    "0.001\n",
    "2.0835494415883846\n",
    "0.01\n",
    "2.0857951094701335\n",
    "\n",
    "Training only with users with > 2 Reviews\n",
    "\n",
    "1e-06 (Lambda)\n",
    "1.9020408071344963 (MSE)\n",
    "1e-05\n",
    "1.8969857580343465\n",
    "0.0001\n",
    "2.016169031546556\n",
    "0.001\n",
    "2.022349450643098\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badeac9",
   "metadata": {},
   "source": [
    "Rating Analysis 4\n",
    "\n",
    "All with duplicates filtered out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2602c",
   "metadata": {},
   "source": [
    "Without filters:\n",
    "\n",
    "1e-06\n",
    "2.028340318325888\n",
    "1e-05\n",
    "1.6938332223303925"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
