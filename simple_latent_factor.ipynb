{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4f625-225f-47a6-80a0-52c689d325a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 5920,
     "status": "ok",
     "timestamp": 1732242186707,
     "user": {
      "displayName": "Tobias Zierl",
      "userId": "15744251128815029584"
     },
     "user_tz": 480
    },
    "id": "13a4f625-225f-47a6-80a0-52c689d325a8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "\n",
    "def SSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('Amazon_Fashion.jsonl.gz', compression='gzip', lines = True)\n",
    "\n",
    "#'df = pd.read_json('Amazon_Fashion.jsonl.gz', compression='gzip', lines = True, chunksize=20) # damit ich nicht so viel ram verbrauche\n",
    "# df = next(df)\n",
    "\n",
    "df = df.sort_values(by = \"timestamp\").drop_duplicates(subset= [\"user_id\", \"asin\"], keep = \"last\")\n",
    "\n",
    "allRatings = df.get([\"user_id\", \"asin\", \"rating\"])\n",
    "# df = df.sample(df.shape[0], replace= False) #shuffle data through sampling without replacement\n",
    "\n",
    "try: \n",
    "    min_reviews = int(sys.argv[1]) \n",
    "except:\n",
    "    min_reviews = 0\n",
    "allRatings_filtered = allRatings[allRatings['user_id'].map(allRatings['user_id'].value_counts()) > min_reviews] \n",
    "\n",
    "# allRatings_numpy = allRatings_filtered.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# training_size = int(allRatings_numpy.size * 0.9)\n",
    "# test_size = allRatings_numpy.size - training_size\n",
    "\n",
    "# ratingsTrain = allRatings_numpy[:training_size]\n",
    "# ratingsValid = allRatings_numpy[-test_size:]\n",
    "\n",
    "ratingsTrain, ratingsValid = train_test_split(allRatings_filtered.to_numpy(), test_size=0.1, shuffle=True)\n",
    "\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "\n",
    "\n",
    "\n",
    "N = ratingsTrain.shape[0]\n",
    "nUsers = len(ratingsPerUser)\n",
    "nItems = len(ratingsPerItem)\n",
    "users = list(ratingsPerUser.keys())\n",
    "items = list(ratingsPerItem.keys())\n",
    "\n",
    "\n",
    "alpha_base = sum([r for _, _, r in ratingsTrain]) / ratingsTrain.shape[0]\n",
    "alpha = alpha_base\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases.get(user, 0) + itemBiases.get(item, 0)\n",
    "\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n",
    "\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in ratingsTrain]\n",
    "    cost = SSE(predictions, labels)\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(ratingsTrain)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for u,i,r in ratingsTrain:\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - r\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)\n",
    "\n",
    "\n",
    "\n",
    "output_file = open(f\"./more_than_{min_reviews}_output_{datetime.datetime.now()}\", \"w\")\n",
    "\n",
    "labels = [r for _, _, r in ratingsTrain]\n",
    "for i in np.power(10., np.arange(-6, -3,1)):\n",
    "    alpha = alpha_base\n",
    "    userBiases = defaultdict(float)\n",
    "    itemBiases = defaultdict(float)\n",
    "    lamb = i\n",
    "    result = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0] * (nUsers + nItems), derivative, args=(labels, lamb))\n",
    "    unpack(result[0])\n",
    "\n",
    "    validMSE = sum((prediction(u,b) - r) ** 2 for u, b, r in ratingsValid) /len(ratingsValid)\n",
    "    print(f\"lambda: {lamb} MSE: {validMSE}\")\n",
    "    output_file.write(f\"lambda: {lamb} MSE: {validMSE}\\n\")\n",
    "\n",
    "output_file.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2602c",
   "metadata": {},
   "source": [
    "# Rating Analysis 4\n",
    "\n",
    "## Details\n",
    "- All with duplicates filtered out\n",
    "- use of the `test_train_split` function by `sklearn`\n",
    "- see results in folder 'run'\n",
    "\n",
    "## Test runs\n",
    "### Condition: more_than_0\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.99971 | 2.03132 | 2.02951 |\n",
    "|   1e-05  | 2.03468 | 1.92611 | 1.92139 |\n",
    "|   0.0001 | 2.00528 | 2.03132 | 1.99967 |\n",
    "\n",
    "### Condition: more_than_1\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.78582 | 1.79589 | 1.79792 |\n",
    "|   1e-05  | 1.78778 | 1.74401 | 1.72535 |\n",
    "|   0.0001 | 1.79751 | 1.8231  | 1.80963 |\n",
    "\n",
    "### Condition: more_than_2\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.7136  | 1.71797 | 1.70042 |\n",
    "|   1e-05  | 1.57232 | 1.57365 | 1.56407 |\n",
    "|   0.0001 | 1.70294 | 1.70694 | 1.64227 |\n",
    "\n",
    "### Condition: more_than_3\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.6984  | 1.71788 | 1.646   |\n",
    "|   1e-05  | 1.47606 | 1.48537 | 1.50144 |\n",
    "|   0.0001 | 1.49987 | 1.48979 | 1.5185  |\n",
    "\n",
    "### Condition: more_than_4\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.58972 | 1.52586 | 1.58443 |\n",
    "|   1e-05  | 1.44104 | 1.44257 | 1.40162 |\n",
    "|   0.0001 | 1.39766 | 1.41456 | 1.37749 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ded099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
