{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a4f625-225f-47a6-80a0-52c689d325a8",
   "metadata": {
    "executionInfo": {
     "elapsed": 5920,
     "status": "ok",
     "timestamp": 1732242186707,
     "user": {
      "displayName": "Tobias Zierl",
      "userId": "15744251128815029584"
     },
     "user_tz": 480
    },
    "id": "13a4f625-225f-47a6-80a0-52c689d325a8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e332da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "\n",
    "def SSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m itemBiases \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    101\u001b[0m lamb \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m--> 102\u001b[0m result \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mfmin_l_bfgs_b(cost, [alpha] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m (nUsers \u001b[38;5;241m+\u001b[39m nItems), derivative, args\u001b[38;5;241m=\u001b[39m(labels, lamb))\n\u001b[1;32m    103\u001b[0m unpack(result[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    105\u001b[0m validMSE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((prediction(u,b) \u001b[38;5;241m-\u001b[39m r) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u, b, r \u001b[38;5;129;01min\u001b[39;00m ratingsValid) \u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(ratingsValid)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:237\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    225\u001b[0m callback \u001b[38;5;241m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m    226\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[0;32m--> 237\u001b[0m res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m    238\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[1;32m    239\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    240\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    241\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    242\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    243\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    244\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m, in \u001b[0;36mcost\u001b[0;34m(theta, labels, lamb)\u001b[0m\n\u001b[1;32m     68\u001b[0m     cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lamb\u001b[38;5;241m*\u001b[39muserBiases[u]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m itemBiases:\n\u001b[0;32m---> 70\u001b[0m     cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lamb\u001b[38;5;241m*\u001b[39mitemBiases[i]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cost\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_json('Amazon_Fashion.jsonl.gz', compression='gzip', lines = True)\n",
    "\n",
    "#'df = pd.read_json('Amazon_Fashion.jsonl.gz', compression='gzip', lines = True, chunksize=20) # damit ich nicht so viel ram verbrauche\n",
    "# df = next(df)\n",
    "\n",
    "df = df.sort_values(by = \"timestamp\").drop_duplicates(subset= [\"user_id\", \"asin\"], keep = \"last\")\n",
    "\n",
    "allRatings = df.get([\"user_id\", \"asin\", \"rating\"])\n",
    "# df = df.sample(df.shape[0], replace= False) #shuffle data through sampling without replacement\n",
    "\n",
    "try: \n",
    "    min_reviews = int(sys.argv[1]) \n",
    "except:\n",
    "    min_reviews = 0\n",
    "allRatings_filtered = allRatings[allRatings['user_id'].map(allRatings['user_id'].value_counts()) > min_reviews] \n",
    "\n",
    "# allRatings_numpy = allRatings_filtered.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# training_size = int(allRatings_numpy.size * 0.9)\n",
    "# test_size = allRatings_numpy.size - training_size\n",
    "\n",
    "# ratingsTrain = allRatings_numpy[:training_size]\n",
    "# ratingsValid = allRatings_numpy[-test_size:]\n",
    "\n",
    "ratingsTrain, ratingsValid = train_test_split(allRatings_filtered.to_numpy(), test_size=0.1, shuffle=True)\n",
    "\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "\n",
    "\n",
    "\n",
    "N = ratingsTrain.shape[0]\n",
    "nUsers = len(ratingsPerUser)\n",
    "nItems = len(ratingsPerItem)\n",
    "users = list(ratingsPerUser.keys())\n",
    "items = list(ratingsPerItem.keys())\n",
    "\n",
    "\n",
    "alpha_base = sum([r for _, _, r in ratingsTrain]) / ratingsTrain.shape[0]\n",
    "alpha = alpha_base\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases.get(user, 0) + itemBiases.get(item, 0)\n",
    "\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n",
    "\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in ratingsTrain]\n",
    "    cost = SSE(predictions, labels)\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(ratingsTrain)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for u,i,r in ratingsTrain:\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - r\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)\n",
    "\n",
    "\n",
    "\n",
    "output_file = open(f\"./more_than_{min_reviews}_output_{datetime.datetime.now()}\", \"w\")\n",
    "\n",
    "labels = [r for _, _, r in ratingsTrain]\n",
    "for i in np.power(10., np.arange(-6, -3,1)):\n",
    "    alpha = alpha_base\n",
    "    userBiases = defaultdict(float)\n",
    "    itemBiases = defaultdict(float)\n",
    "    lamb = i\n",
    "    result = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0] * (nUsers + nItems), derivative, args=(labels, lamb))\n",
    "    unpack(result[0])\n",
    "\n",
    "    validMSE = sum((prediction(u,b) - r) ** 2 for u, b, r in ratingsValid) /len(ratingsValid)\n",
    "    print(f\"lambda: {lamb} MSE: {validMSE}\")\n",
    "    output_file.write(f\"lambda: {lamb} MSE: {validMSE}\\n\")\n",
    "\n",
    "output_file.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2602c",
   "metadata": {},
   "source": [
    "# Rating Analysis 4\n",
    "\n",
    "## Details\n",
    "- All with duplicates filtered out\n",
    "- use of the `test_train_split` function by `sklearn`\n",
    "- see results in folder 'run'\n",
    "\n",
    "## Test runs\n",
    "### Condition: more_than_0\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.99971 | 2.03132 | 2.02951 |\n",
    "|   1e-05  | 2.03468 | 1.92611 | 1.92139 |\n",
    "|   0.0001 | 2.00528 | 2.03132 | 1.99967 |\n",
    "\n",
    "### Condition: more_than_1\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.78582 | 1.79589 | 1.79792 |\n",
    "|   1e-05  | 1.78778 | 1.74401 | 1.72535 |\n",
    "|   0.0001 | 1.79751 | 1.8231  | 1.80963 |\n",
    "\n",
    "### Condition: more_than_2\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.7136  | 1.71797 | 1.70042 |\n",
    "|   1e-05  | 1.57232 | 1.57365 | 1.56407 |\n",
    "|   0.0001 | 1.70294 | 1.70694 | 1.64227 |\n",
    "\n",
    "### Condition: more_than_3\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.6984  | 1.71788 | 1.646   |\n",
    "|   1e-05  | 1.47606 | 1.48537 | 1.50144 |\n",
    "|   0.0001 | 1.49987 | 1.48979 | 1.5185  |\n",
    "\n",
    "### Condition: more_than_4\n",
    "|   Lambda |    run1 |    run2 |    run3 |\n",
    "|---------:|--------:|--------:|--------:|\n",
    "|   1e-06  | 1.58972 | 1.52586 | 1.58443 |\n",
    "|   1e-05  | 1.44104 | 1.44257 | 1.40162 |\n",
    "|   0.0001 | 1.39766 | 1.41456 | 1.37749 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ded099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
